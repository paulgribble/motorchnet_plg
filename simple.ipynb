{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-05T16:46:38.786827Z",
     "iopub.status.busy": "2023-11-05T16:46:38.786005Z",
     "iopub.status.idle": "2023-11-05T16:46:43.068632Z",
     "shell.execute_reply": "2023-11-05T16:46:43.068304Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import motornet as mn\n",
    "from task import CentreOutFFMinJerk\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('All packages imported.')\n",
    "print('pytorch version: ' + th.__version__)\n",
    "print('numpy version: ' + np.__version__)\n",
    "print('motornet version: ' + mn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T16:46:43.085520Z",
     "iopub.status.busy": "2023-11-05T16:46:43.085367Z",
     "iopub.status.idle": "2023-11-05T16:46:43.094339Z",
     "shell.execute_reply": "2023-11-05T16:46:43.094082Z"
    }
   },
   "outputs": [],
   "source": [
    "effector = mn.effector.RigidTendonArm26(muscle=mn.muscle.RigidTendonHillMuscle())\n",
    "env = CentreOutFFMinJerk(effector=effector, max_ep_duration=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-05T16:46:43.095927Z",
     "iopub.status.busy": "2023-11-05T16:46:43.095838Z",
     "iopub.status.idle": "2023-11-05T16:46:43.452451Z",
     "shell.execute_reply": "2023-11-05T16:46:43.452154Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(th.nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.gru = th.nn.GRU(input_dim, hidden_dim, 1, batch_first=True)\n",
    "        self.fc = th.nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = th.nn.Sigmoid()\n",
    "\n",
    "        # the default initialization in torch isn't ideal\n",
    "        for name, param in self.named_parameters():\n",
    "            if name == \"gru.weight_ih_l0\":\n",
    "                th.nn.init.xavier_uniform_(param)\n",
    "            elif name == \"gru.weight_hh_l0\":\n",
    "                th.nn.init.orthogonal_(param)\n",
    "            elif name == \"gru.bias_ih_l0\":\n",
    "                th.nn.init.zeros_(param)\n",
    "            elif name == \"gru.bias_hh_l0\":\n",
    "                th.nn.init.zeros_(param)\n",
    "            elif name == \"fc.weight\":\n",
    "                th.nn.init.xavier_uniform_(param)\n",
    "            elif name == \"fc.bias\":\n",
    "                th.nn.init.constant_(param, -5.)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, h0):\n",
    "        y, h = self.gru(x[:, None, :], h0)\n",
    "        u = self.sigmoid(self.fc(y)).squeeze(dim=1)\n",
    "        return u, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(self.device)\n",
    "        return hidden\n",
    "    \n",
    "device = th.device(\"cpu\")\n",
    "\n",
    "policy = Policy(env.observation_space.shape[0], 128, env.n_muscles, device=device)\n",
    "optimizer = th.optim.Adam(policy.parameters(), lr=10**-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T16:46:43.454293Z",
     "iopub.status.busy": "2023-11-05T16:46:43.454155Z",
     "iopub.status.idle": "2023-11-05T16:46:43.456047Z",
     "shell.execute_reply": "2023-11-05T16:46:43.455799Z"
    }
   },
   "outputs": [],
   "source": [
    "def l1(x, y):\n",
    "    \"\"\"L1 loss\"\"\"\n",
    "    return th.mean(th.sum(th.abs(x - y), dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-11-05T16:46:43.457532Z",
     "iopub.status.busy": "2023-11-05T16:46:43.457432Z",
     "iopub.status.idle": "2023-11-05T17:05:56.568128Z",
     "shell.execute_reply": "2023-11-05T17:05:56.567464Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_batch    = 10000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for batch in tqdm(range(n_batch), desc=f\"Training {n_batch} batches of {batch_size}\", unit=\"batch\"):\n",
    "    # initialize batch\n",
    "    h = policy.init_hidden(batch_size=batch_size)\n",
    "    obs, info = env.reset(options={\"batch_size\": batch_size})\n",
    "    terminated = False\n",
    "\n",
    "    # initial positions and targets\n",
    "    xy = [info[\"states\"][\"fingertip\"][:, None, :]]\n",
    "    tg = [info[\"goal\"][:, None, :]]\n",
    "\n",
    "    # simulate whole episode\n",
    "    while not terminated:  # will run until `max_ep_duration` is reached\n",
    "        action, h = policy(obs, h)\n",
    "        obs, reward, terminated, truncated, info = env.step(action=action)\n",
    "\n",
    "        xy.append(info[\"states\"][\"fingertip\"][:, None, :])  # trajectories\n",
    "        tg.append(info[\"goal\"][:, None, :])  # targets\n",
    "\n",
    "    # concatenate into a (batch_size, n_timesteps, xy) tensor\n",
    "    xy = th.cat(xy, axis=1)\n",
    "    tg = th.cat(tg, axis=1)\n",
    "    loss = l1(xy, tg)\n",
    "\n",
    "    # backward pass & update weights\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    th.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=1.)  # important!\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = 'simple_weights'\n",
    "log_file    = 'simple_log.json'\n",
    "cfg_file    = 'simple_cfg.json'\n",
    "\n",
    "# save model weights\n",
    "th.save(policy.state_dict(), weight_file)\n",
    "\n",
    "# save training history (log)\n",
    "with open(log_file, 'w') as file:\n",
    "    json.dump({'losses':losses}, file)\n",
    "\n",
    "# save environment configuration dictionary\n",
    "cfg = env.get_save_config()\n",
    "with open(cfg_file, 'w') as file:\n",
    "    json.dump(cfg, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:05:56.570990Z",
     "iopub.status.busy": "2023-11-05T17:05:56.570776Z",
     "iopub.status.idle": "2023-11-05T17:05:56.814459Z",
     "shell.execute_reply": "2023-11-05T17:05:56.814139Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_log(log):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  fig.set_tight_layout(True)\n",
    "  fig.set_size_inches((8, 3))\n",
    "\n",
    "  axs.semilogy(log)\n",
    "\n",
    "  axs.set_ylabel(\"Loss\")\n",
    "  axs.set_xlabel(\"Batch #\")\n",
    "  plt.show()\n",
    "\n",
    "plot_training_log(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-05T17:05:56.816217Z",
     "iopub.status.busy": "2023-11-05T17:05:56.816076Z",
     "iopub.status.idle": "2023-11-05T17:05:57.754990Z",
     "shell.execute_reply": "2023-11-05T17:05:57.754694Z"
    }
   },
   "outputs": [],
   "source": [
    "plotor = mn.plotor.plot_pos_over_time\n",
    "\n",
    "def plot_simulations(xy, target_xy):\n",
    "  target_x = target_xy[:, -1, 0]\n",
    "  target_y = target_xy[:, -1, 1]\n",
    "\n",
    "  plt.figure(figsize=(10,3))\n",
    "\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.ylim([-1.1, 1.1])\n",
    "  plt.xlim([-1.1, 1.1])\n",
    "  plotor(axis=plt.gca(), cart_results=xy)\n",
    "  plt.scatter(target_x, target_y)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.ylim([-2, 2])\n",
    "  plt.xlim([-2, 2])\n",
    "  plotor(axis=plt.gca(), cart_results=xy - target_xy)\n",
    "  plt.axhline(0, c=\"grey\")\n",
    "  plt.axvline(0, c=\"grey\")\n",
    "  plt.xlabel(\"X distance to target\")\n",
    "  plt.ylabel(\"Y distance to target\")\n",
    "  plt.show()\n",
    "\n",
    "plot_simulations(xy=th.detach(xy), target_xy=th.detach(tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tg[13,:,:].numpy(),'--')\n",
    "plt.plot(xy[13,:,:].detach().numpy(),'-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
